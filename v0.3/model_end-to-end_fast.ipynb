{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.16.19)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (1.19.19)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3) (0.3.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.19->boto3) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.19->boto3) (1.25.10)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.19->boto3) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: watchtower in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.0)\n",
      "Requirement already satisfied: boto3<2,>=1.9.253 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from watchtower) (1.16.19)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2,>=1.9.253->watchtower) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2,>=1.9.253->watchtower) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3<2,>=1.9.253->watchtower) (1.19.19)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.19->boto3<2,>=1.9.253->watchtower) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.19->boto3<2,>=1.9.253->watchtower) (1.25.10)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.19->boto3<2,>=1.9.253->watchtower) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: s3fs==0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.4.2)\n",
      "Requirement already satisfied: botocore>=1.12.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs==0.4.2) (1.19.19)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from s3fs==0.4.2) (0.6.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs==0.4.2) (1.25.10)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs==0.4.2) (2.8.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.12.91->s3fs==0.4.2) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore>=1.12.91->s3fs==0.4.2) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting pyathena\n",
      "  Downloading PyAthena-2.0.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: botocore>=1.5.52 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (1.19.19)\n",
      "Collecting tenacity>=4.1.0\n",
      "  Downloading tenacity-6.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: boto3>=1.4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyathena) (1.16.19)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (1.25.10)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore>=1.5.52->pyathena) (0.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tenacity>=4.1.0->pyathena) (1.14.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3>=1.4.4->pyathena) (0.3.3)\n",
      "Installing collected packages: tenacity, pyathena\n",
      "Successfully installed pyathena-2.0.0 tenacity-6.2.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.1.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib) (1.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (45.2.0.post20200210)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scipy) (1.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipywidgets) (7.12.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipywidgets) (5.1.4)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipywidgets) (5.0.4)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets) (4.4.1)\n",
      "Requirement already satisfied: ipython-genutils in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (45.2.0.post20200210)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.0.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: jupyter-core in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.6.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.5.2)\n",
      "Requirement already satisfied: prometheus-client in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.1)\n",
      "Requirement already satisfied: Send2Trash in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (18.1.1)\n",
      "Requirement already satisfied: nbconvert in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.15.7)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: bleach in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: testpath in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1)\n",
      "Requirement already satisfied: webencodings in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.6)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.22.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-learn) (1.18.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: | \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/linux-64::pandas==1.0.1=py36h0573a6f_0\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::scikit-learn==0.22.1=py36hd81dba3_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::bkcharts==0.2=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/linux-64::pytest-arraydiff==0.3=py36h39e3cac_0\n",
      "  - defaults/linux-64::bottleneck==1.3.2=py36heb32a55_0\n",
      "  - defaults/linux-64::pywavelets==1.1.1=py36h7b6447c_0\n",
      "  - defaults/noarch::pytest-astropy==0.8.0=py_0\n",
      "  - defaults/linux-64::numexpr==2.7.1=py36h423224d_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/linux-64::h5py==2.10.0=py36h7918eee_0\n",
      "  - defaults/linux-64::bokeh==1.4.0=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::numpy-base==1.18.1=py36hde5b4d6_1\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::astropy==4.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::patsy==0.5.1=py36_0\n",
      "  - defaults/linux-64::scikit-image==0.16.2=py36h0573a6f_0\n",
      "  - defaults/linux-64::matplotlib-base==3.1.3=py36hef1b27d_0\n",
      "  - defaults/linux-64::imageio==2.6.1=py36_0\n",
      "  - defaults/linux-64::pytables==3.6.1=py36h71ec239_0\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::mkl_fft==1.0.15=py36ha843d7b_0\n",
      "  - defaults/linux-64::statsmodels==0.11.0=py36h7b6447c_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/noarch::seaborn==0.10.0=py_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/linux-64::numba==0.48.0=py36h0573a6f_0\n",
      "  - defaults/linux-64::scipy==1.4.1=py36h0b6359f_0\n",
      "  - defaults/noarch::pytest-doctestplus==0.5.0=py_0\n",
      "  - defaults/linux-64::mkl_random==1.1.0=py36hd6b4f25_0\n",
      "  - defaults/noarch::dask==2.11.0=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::matplotlib==3.1.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "  - defaults/linux-64::numpy==1.18.1=py36h4f9e942_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - defaults/noarch::jupyterlab==1.2.6=pyhf63ae98_0\n",
      "  - defaults/linux-64::python-language-server==0.31.7=py36_0\n",
      "  - defaults/linux-64::nb_conda==2.2.1=py36_0\n",
      "  - defaults/noarch::numpydoc==0.9.2=py_0\n",
      "  - defaults/noarch::anaconda-project==0.8.4=py_0\n",
      "  - defaults/linux-64::nbconvert==5.6.1=py36_0\n",
      "  - defaults/linux-64::bokeh==1.4.0=py36_0\n",
      "  - defaults/noarch::jupyterlab_server==1.0.6=py_0\n",
      "  - defaults/linux-64::jupyter==1.0.0=py36_7\n",
      "  - defaults/linux-64::scikit-image==0.16.2=py36h0573a6f_0\n",
      "  - defaults/linux-64::imageio==2.6.1=py36_0\n",
      "  - defaults/linux-64::nb_conda_kernels==2.2.4=py36_0\n",
      "  - defaults/linux-64::spyder==4.0.1=py36_0\n",
      "  - defaults/linux-64::requests==2.22.0=py36_1\n",
      "  - defaults/noarch::dask==2.11.0=py_0\n",
      "  - defaults/noarch::ipywidgets==7.5.1=py_0\n",
      "  - defaults/linux-64::widgetsnbextension==3.5.1=py36_0\n",
      "  - defaults/noarch::s3fs==0.4.2=py_0\n",
      "  - defaults/linux-64::notebook==6.0.3=py36_0\n",
      "  - defaults/linux-64::anaconda-client==1.7.2=py36_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.3\n",
      "  latest version: 4.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - implicit\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    astroid-2.4.2              |   py36h9f0ad1d_1         297 KB  conda-forge\n",
      "    boto3-1.16.31              |     pyhd8ed1ab_0          70 KB  conda-forge\n",
      "    botocore-1.19.31           |     pyhd8ed1ab_0         4.3 MB  conda-forge\n",
      "    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n",
      "    certifi-2020.12.5          |   py36h5fab9bb_0         143 KB  conda-forge\n",
      "    docutils-0.16              |   py36h9880bd3_2         736 KB  conda-forge\n",
      "    implicit-0.4.2             |   py36h830a2c2_1         732 KB  conda-forge\n",
      "    pillow-7.1.2               |   py36hb39fc2d_0         604 KB\n",
      "    pylint-2.6.0               |   py36h9f0ad1d_1         446 KB  conda-forge\n",
      "    sphinx-3.3.1               |     pyhd8ed1ab_0         1.5 MB  conda-forge\n",
      "    toml-0.10.2                |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  astroid            conda-forge/linux-64::astroid-2.4.2-py36h9f0ad1d_1\n",
      "  bleach             conda-forge/noarch::bleach-3.2.1-pyh9f0ad1d_0\n",
      "  boto3              conda-forge/noarch::boto3-1.16.31-pyhd8ed1ab_0\n",
      "  botocore           conda-forge/noarch::botocore-1.19.31-pyhd8ed1ab_0\n",
      "  brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py36he6145b8_1001\n",
      "  docutils           conda-forge/linux-64::docutils-0.16-py36h9880bd3_2\n",
      "  implicit           conda-forge/linux-64::implicit-0.4.2-py36h830a2c2_1\n",
      "  pillow             pkgs/main/linux-64::pillow-7.1.2-py36hb39fc2d_0\n",
      "  pylint             conda-forge/linux-64::pylint-2.6.0-py36h9f0ad1d_1\n",
      "  s3transfer         conda-forge/noarch::s3transfer-0.3.3-py_3\n",
      "  sphinx             conda-forge/noarch::sphinx-3.3.1-pyhd8ed1ab_0\n",
      "  toml               conda-forge/noarch::toml-0.10.2-pyhd8ed1ab_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.25.11-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2020.6.20-hecda079_0 --> 2020.12.5-ha878542_0\n",
      "  certifi                          2020.6.20-py36h9880bd3_2 --> 2020.12.5-py36h5fab9bb_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "astroid-2.4.2        | 297 KB    | ##################################### | 100% \n",
      "toml-0.10.2          | 18 KB     | ##################################### | 100% \n",
      "boto3-1.16.31        | 70 KB     | ##################################### | 100% \n",
      "docutils-0.16        | 736 KB    | ##################################### | 100% \n",
      "sphinx-3.3.1         | 1.5 MB    | ##################################### | 100% \n",
      "certifi-2020.12.5    | 143 KB    | ##################################### | 100% \n",
      "ca-certificates-2020 | 137 KB    | ##################################### | 100% \n",
      "pylint-2.6.0         | 446 KB    | ##################################### | 100% \n",
      "implicit-0.4.2       | 732 KB    | ##################################### | 100% \n",
      "botocore-1.19.31     | 4.3 MB    | ##################################### | 100% \n",
      "pillow-7.1.2         | 604 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting jupyter_client\n",
      "  Downloading jupyter_client-6.1.7-py3-none-any.whl (108 kB)\n",
      "\u001b[K     |████████████████████████████████| 108 kB 13.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: pyzmq>=13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter_client) (18.1.1)\n",
      "Requirement already satisfied, skipping upgrade: traitlets in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter_client) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter_client) (6.0.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter_client) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: jupyter-core>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jupyter_client) (4.6.1)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets->jupyter_client) (4.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets->jupyter_client) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from traitlets->jupyter_client) (0.2.0)\n",
      "Installing collected packages: jupyter-client\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 5.3.4\n",
      "    Uninstalling jupyter-client-5.3.4:\n",
      "      Successfully uninstalled jupyter-client-5.3.4\n",
      "Successfully installed jupyter-client-6.1.7\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install boto3\n",
    "! pip install watchtower\n",
    "! pip install s3fs==0.4.2\n",
    "! pip install pyathena\n",
    "! pip install matplotlib\n",
    "! pip install scipy\n",
    "! pip install ipywidgets\n",
    "! pip install scikit-learn\n",
    "\n",
    "! conda install -c conda-forge --yes implicit \n",
    "\n",
    "! pip install --upgrade jupyter_client # useful to make ipywidgets work properly when fitting data with implicit\n",
    "\n",
    "# pip install git+https://gitlab.com/cloena/cloena-aws-tools.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/aws_tools/project_config.py:18: UserWarning: no aws_config.json file found\n",
      "  warnings.warn('no aws_config.json file found')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import implicit\n",
    "\n",
    "from aws_tools import athena_tools, s3_tools\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import re\n",
    "\n",
    "import scipy\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "import boto3\n",
    "import csv\n",
    "\n",
    "from pyathena import connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to Athena\n",
    "conn = connect(s3_staging_dir = 's3://aws-athena-query-results-341377015103-eu-west-2/',\n",
    "                   region_name='eu-west-2') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the 'views' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rows]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "DROP TABLE IF EXISTS bt_home_ds.bt_tv_recommendation_engine_data_views;\n",
    "'''\n",
    "pd.read_sql(query, conn)\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS bt_home_ds.bt_tv_recommendation_engine_data_views AS\n",
    "SELECT\n",
    "    vs.VISION_SERVICE_ID AS id_user -- account ID\n",
    "    ,vs.CI_ASSET_TYPE AS TYPE_ASSET -- e.g. Film, Music, etc.\n",
    "    ,vs.VIEW_TIME_ST AS EVENT_DATE -- time of event\n",
    "    \n",
    "    ,COALESCE(ps2.EDITORIAL_VERSION_ID, ps1.EDITORIAL_VERSION_ID) AS id_editorial -- identifies multiple instances of same film/season/episode, e.g. rent/purchase & SD/HD\n",
    "    \n",
    "    ,COALESCE(ps2.CI_TITLE, ps1.CI_TITLE) AS TITLE --  human readable title\n",
    "    ,COALESCE(ps2.CI_TYPE, ps1.CI_TYPE) AS TYPE -- type, like film/music/episode/season/collection\n",
    "    ,COALESCE(ps2.CI_AVAILABLE_END_DT, ps1.CI_AVAILABLE_END_DT) AS END_DATE -- date until availability of item\n",
    "    ,COALESCE(ps2.GENRE, ps1.GENRE) AS GENRE\n",
    "    ,COALESCE(ps2.rating, ps1.rating) AS rating\n",
    "      \n",
    "    ,'VIEW' AS type_entitlement\n",
    "    \n",
    "FROM\n",
    "    bt_home_datamart.l_edw_vod_views vs\n",
    "\n",
    "-- perform an inner join of the events with the catalogue to get the product id for each entry:\n",
    "-- this is needed to later match the product if with the parent id and group episodes into seasons\n",
    "INNER JOIN \n",
    "    bt_home_datamart.l_edw_vod_products ps1\n",
    "ON\n",
    "     vs.CONTENT_ID = ps1.PRODUCT_GUID\n",
    "\n",
    "-- perform left join to match ID_PARENT with product id where available:\n",
    "-- this will give either the same element due to the coalesce OR the actual parent, i.e. the season rather than the episode\n",
    "LEFT JOIN \n",
    "   bt_home_datamart.l_edw_vod_products ps2\n",
    "ON\n",
    "   ps1.CI_PARENTGUID = ps2.PRODUCT_GUID \n",
    "\n",
    "WHERE vs.EVENT_SLOT_TYPE = 'Feature'\n",
    "AND vs.VISION_SERVICE_ID IS NOT NULL\n",
    "AND ps1.EDITORIAL_VERSION_ID IS NOT NULL;\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [rows]\n",
       "Index: []"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "DROP TABLE IF EXISTS bt_home_ds.bt_tv_recommendation_engine_data_views_maxenddt;\n",
    "'''\n",
    "pd.read_sql(query, conn)\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS bt_home_ds.bt_tv_recommendation_engine_data_views_maxenddt AS\n",
    "SELECT \n",
    "    aaa.id_user -- account ID\n",
    "    ,aaa.TYPE_ASSET -- e.g. Film, Music, etc.\n",
    "    ,aaa.EVENT_DATE -- time of event\n",
    "    \n",
    "    ,aaa.id_editorial -- identifies multiple instances of same film/season/episode, e.g. rent/purchase & SD/HD\n",
    "    \n",
    "    ,aaa.TITLE --  human readable title\n",
    "    ,aaa.TYPE -- type, like film/music/episode/season/collection\n",
    "    \n",
    "    ,COALESCE(ps.CI_AVAILABLE_END_DT, aaa.END_DATE) AS END_DATE -- date until availability of item\n",
    "    \n",
    "    ,aaa.GENRE\n",
    "    ,aaa.rating\n",
    "    \n",
    "    ,aaa.type_entitlement -- TVOD / EVOD / PPV\n",
    "\n",
    "FROM bt_home_ds.bt_tv_recommendation_engine_data_views aaa\n",
    "\n",
    "-- left join with catalogue again where we keep only max availability date for each editorial id\n",
    "LEFT JOIN\n",
    "    (SELECT EDITORIAL_VERSION_ID, MAX(DATE(CI_AVAILABLE_END_DT)) AS CI_AVAILABLE_END_DT\n",
    "    FROM bt_home_datamart.l_edw_vod_products \n",
    "    GROUP BY EDITORIAL_VERSION_ID) ps\n",
    "ON \n",
    "    aaa.id_editorial = ps.EDITORIAL_VERSION_ID;\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-12-08 13:35:59,617 [INFO ]  starting Athena query ...\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM bt_home_ds.bt_tv_recommendation_engine_data_views_maxenddt;\n",
    "\"\"\"\n",
    "\n",
    "data_views = athena_tools.AthenaQuerier().execute_query(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the 'purchase'/'rental'/'PPV' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "DROP TABLE IF EXISTS bt_home_ds.bt_tv_recommendation_engine_data_prps;\n",
    "'''\n",
    "pd.read_sql(query, conn)\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS bt_home_ds.bt_tv_recommendation_engine_data_prps AS\n",
    "SELECT\n",
    "    vs.VISION_SERVICE_ID AS id_user -- account ID\n",
    "    ,vs.CI_ASSET_TYPE AS TYPE_ASSET -- e.g. Film, Music, etc.\n",
    "    ,vs.PURCHASE_TIME_ST AS EVENT_DATE -- time of event\n",
    "    \n",
    "    ,COALESCE(ps2.EDITORIAL_VERSION_ID, ps1.EDITORIAL_VERSION_ID) AS id_editorial -- identifies multiple instances of same film/season/episode, e.g. rent/purchase & SD/HD\n",
    "    \n",
    "    ,COALESCE(ps2.CI_TITLE, ps1.CI_TITLE) AS TITLE --  human readable title\n",
    "    ,COALESCE(ps2.CI_TYPE, ps1.CI_TYPE) AS TYPE -- type, like film/music/episode/season/collection\n",
    "    \n",
    "    ,COALESCE(ps3.CI_AVAILABLE_END_DT, ps2.CI_AVAILABLE_END_DT, ps1.CI_AVAILABLE_END_DT) AS END_DATE -- date until availability of item\n",
    "    \n",
    "    ,COALESCE(ps2.GENRE, ps1.GENRE) AS GENRE\n",
    "    ,COALESCE(ps2.rating, ps1.rating) AS rating\n",
    "    \n",
    "    ,vs.ENTITLEMENT_TYPE AS type_entitlement -- TVOD / EVOD / PPV\n",
    "    \n",
    "FROM\n",
    "    bt_home_datamart.l_edw_vod_purchases vs\n",
    "\n",
    "-- perform an inner join of the events with the catalogue to get the product id for each entry:\n",
    "-- this is needed to later match the product if with the parent id and group episodes into seasons\n",
    "INNER JOIN \n",
    "    bt_home_datamart.l_edw_vod_products ps1\n",
    "ON\n",
    "    vs.PRODUCT_ID = ps1.PRODUCT_GUID\n",
    "\n",
    "-- perform left join to match ID_PARENT with product id where available:\n",
    "-- this will give either the same element due to the coalesce OR the actual parent, i.e. the season rather than the episode\n",
    "LEFT JOIN \n",
    "   bt_home_datamart.l_edw_vod_products ps2\n",
    "ON\n",
    "   ps1.CI_PARENTGUID = ps2.PRODUCT_GUID \n",
    "   \n",
    "-- left join with catalogue again where we keep only max availability date for each editorial id\n",
    "LEFT JOIN\n",
    "    (SELECT EDITORIAL_VERSION_ID, MAX(DATE(CI_AVAILABLE_END_DT)) AS CI_AVAILABLE_END_DT\n",
    "    FROM bt_home_datamart.l_edw_vod_products \n",
    "    GROUP BY EDITORIAL_VERSION_ID) ps3\n",
    "ON \n",
    "    id_editorial = ps3.EDITORIAL_VERSION_ID\n",
    "\n",
    "WHERE vs.VISION_SERVICE_ID IS NOT NULL\n",
    "AND ps2.EDITORIAL_VERSION_ID IS NOT NULL;\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "DROP TABLE IF EXISTS bt_home_ds.bt_tv_recommendation_engine_data_prps_maxenddt;\n",
    "'''\n",
    "pd.read_sql(query, conn)\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE IF NOT EXISTS bt_home_ds.bt_tv_recommendation_engine_data_prps_maxenddt AS\n",
    "SELECT\n",
    "    aaa.id_user -- account ID\n",
    "    ,aaa.TYPE_ASSET -- e.g. Film, Music, etc.\n",
    "    ,aaa.EVENT_DATE -- time of event\n",
    "    \n",
    "    ,aaa.id_editorial -- identifies multiple instances of same film/season/episode, e.g. rent/purchase & SD/HD\n",
    "    \n",
    "    ,aaa.TITLE --  human readable title\n",
    "    ,aaa.TYPE -- type, like film/music/episode/season/collection\n",
    "    \n",
    "    ,COALESCE(ps.CI_AVAILABLE_END_DT, aaa.END_DATE) AS END_DATE -- date until availability of item\n",
    "    \n",
    "    ,aaa.GENRE\n",
    "    ,aaa.rating\n",
    "    \n",
    "    ,aaa.type_entitlement -- TVOD / EVOD / PPV\n",
    "    \n",
    "FROM\n",
    "    bt_home_ds.bt_tv_recommendation_engine_data_prps aaa\n",
    "\n",
    "-- left join with catalogue again where we keep only max availability date for each editorial id\n",
    "LEFT JOIN\n",
    "    (SELECT EDITORIAL_VERSION_ID, MAX(DATE(CI_AVAILABLE_END_DT)) AS CI_AVAILABLE_END_DT\n",
    "    FROM bt_home_datamart.l_edw_vod_products \n",
    "    GROUP BY EDITORIAL_VERSION_ID) ps\n",
    "ON \n",
    "    aaa.id_editorial = ps.EDITORIAL_VERSION_ID;\n",
    "'''\n",
    "pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT *\n",
    "FROM bt_home_ds.bt_tv_recommendation_engine_data_prps_maxenddt;\n",
    "\"\"\"\n",
    "\n",
    "data_prps = athena_tools.AthenaQuerier().execute_query(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit = data_views.append(data_prps, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_views\n",
    "del data_prps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit['type_asset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_MUSIC = True\n",
    "if DROP_MUSIC:\n",
    "    data_implicit = data_implicit[(data_implicit['type_asset'] != 'Music') & (data_implicit['type_asset'] != 'music')]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Richard's export from the hackathon\n",
    "# season_to_brand_map = pd.read_csv('s3://bt-data-science-playground/bt-tv-recommendation-system/model_objects/SeasonToBrandMapping-NoExpired.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_to_brand_map = pd.read_csv('s3://bt-data-science-playground/bt-tv-recommendation-system/model_objects/New-SeasonToBrandMapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_to_brand_map.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season_to_brand(df, df_map):\n",
    "    df = df.merge(df_map, how='left', left_on = 'id_editorial', right_on = 'SEASON_GUID')\n",
    "    df['BRAND_GUID'].fillna(df['id_editorial'], inplace=True)\n",
    "    df['id_editorial'] = df['BRAND_GUID']\n",
    "    df.drop(['SEASON_GUID', 'BRAND_GUID'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit = season_to_brand(data_implicit, season_to_brand_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sparsity \n",
    "n_users = data_implicit['id_user'].unique().shape[0]\n",
    "n_items = data_implicit['id_editorial'].unique().shape[0]\n",
    "\n",
    "print('Number of users: {}'.format(n_users))\n",
    "print('Number of items: {}'.format(n_items))\n",
    "print('Sparsity: {:4.3f}%'.format(float(data_implicit.shape[0]) / float(n_users*n_items) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many users have watched X% of the content\n",
    "idx = data_implicit['id_user'].value_counts().index.tolist()\n",
    "counts = data_implicit['id_user'].value_counts().tolist()\n",
    "\n",
    "user_count = []\n",
    "percentage_activity = []\n",
    "activity_so_far = 0\n",
    "total_activity = sum(counts)\n",
    "\n",
    "for u in range(len(idx)):\n",
    "    \n",
    "    user_count.append(u+1)\n",
    "    \n",
    "    activity_so_far = activity_so_far + counts[u]\n",
    "    percentage_so_far = activity_so_far / total_activity * 100\n",
    "    percentage_activity.append(percentage_so_far)\n",
    "     \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(user_count, percentage_activity)\n",
    "plt.xlabel('User count')\n",
    "plt.ylabel('Total # of activity [%]')\n",
    "plt.grid()\n",
    "plt.yticks(np.arange(0,105, 5))\n",
    "plt.xticks(np.arange(0,1000000, 150000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit['type_entitlement'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on type of entitlement (purchase/rental/ppv/view) give different strength [EVOD=purchase;TVOD=rental]\n",
    "def assign_eventStrength(x):\n",
    "    if x == 'EVOD':\n",
    "        val = 3\n",
    "    elif x == 'TVOD':\n",
    "        val = 3\n",
    "    elif x == 'PPV':\n",
    "        val = 3\n",
    "    elif x == 'VIEW':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "\n",
    "data_implicit['eventStrength'] = data_implicit['type_entitlement'].apply(assign_eventStrength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn duplicate the rating column in a form that is numeric so that they can be compared\n",
    "def rating_toNumeric(x):\n",
    "    if x == 'u':\n",
    "        return 0\n",
    "    elif x == 'pg':\n",
    "        return 1\n",
    "    elif x == '12':\n",
    "        return 2\n",
    "    elif x == '15':\n",
    "        return 3\n",
    "    elif x == '18':\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "    \n",
    "data_implicit['rating_n'] = data_implicit['rating'].apply(rating_toNumeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_production(x):\n",
    "    if (x == 'season') or (x == 'episode'):\n",
    "        return 'BRAND'\n",
    "    elif x == 'collection':\n",
    "        return 'COLLECTION'\n",
    "    else:\n",
    "        return 'PROGRAM'\n",
    "    \n",
    "data_implicit['type_production'] = data_implicit['type'].apply(type_production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit['title'] = data_implicit['title'].astype(\"category\")\n",
    "data_implicit['id_user'] = data_implicit['id_user'].astype(\"category\")\n",
    "data_implicit['id_editorial'] = data_implicit['id_editorial'].astype(\"category\")\n",
    "data_implicit['id_user_simple'] = data_implicit['id_user'].cat.codes\n",
    "data_implicit['id_editorial_simple'] = data_implicit['id_editorial'].cat.codes\n",
    "\n",
    "data_implicit.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_content_person = scipy.sparse.csr_matrix(\n",
    "    (data_implicit['eventStrength'].astype(float), (data_implicit['id_editorial_simple'], data_implicit['id_user_simple']))\n",
    ")\n",
    "sparse_person_content = scipy.sparse.csr_matrix(\n",
    "    (data_implicit['eventStrength'].astype(float), (data_implicit['id_user_simple'], data_implicit['id_editorial_simple']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=30, regularization=0.1, iterations=50)\n",
    "alpha = 15\n",
    "data_tofit = (sparse_content_person * alpha).astype('double')\n",
    "model.fit(data_tofit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the trained person and content vectors. We convert them to csr matrices\n",
    "# person_vecs = scipy.sparse.csr_matrix(model.user_factors)\n",
    "# content_vecs = scipy.sparse.csr_matrix(model.item_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start making recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_editorial_legend = data_implicit[['id_editorial', 'id_editorial_simple', 'type_production', 'end_date']].drop_duplicates(subset=['id_editorial', 'id_editorial_simple']).sort_values(by='id_editorial_simple')\n",
    "\n",
    "id_editorial_simple_list = id_editorial_legend['id_editorial_simple'].tolist()\n",
    "id_editorial_list = id_editorial_legend['id_editorial'].tolist()\n",
    "type_production_list = id_editorial_legend['type_production'].tolist()\n",
    "\n",
    "# get array with 1 or 0 based on availability of content today\n",
    "availability = id_editorial_legend['end_date'] > datetime.today().strftime('%Y-%m-%d')\n",
    "availability = np.array(availability.astype(int))\n",
    "\n",
    "\n",
    "id_user_legend = data_implicit[['id_user', 'id_user_simple']].drop_duplicates(subset=['id_user', 'id_user_simple']).sort_values(by='id_user_simple')\n",
    "id_user_simple_list = id_user_legend['id_user_simple'].tolist()\n",
    "id_user_list = id_user_legend['id_user'].tolist()\n",
    "\n",
    "date_today = datetime.today().strftime('%Y-%m-%d')\n",
    "code_version = 'v0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_editorial_legend.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_implicit[data_implicit['id_editorial_simple'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_user_legend.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Like This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_similar = np.shape(model.item_factors)[0] # do it for all\n",
    "\n",
    "content_vecs = model.item_factors\n",
    "\n",
    "content_norms = np.sqrt((content_vecs * content_vecs).sum(axis=1)) # i.e. calculating abs. value of the vector of each item -->  |A|\n",
    "\n",
    "def more_like_this(content_id):\n",
    "    \n",
    "    scores = content_vecs.dot(content_vecs[content_id,:])  / (content_norms * content_vecs[content_id,:].sum()) # i.e. calculating cosine similarity, (A.B) / (|A| x |B|) --> |B| just a constant so effectively won't need it\n",
    "    \n",
    "    scores =  MinMaxScaler().fit_transform(scores.reshape(-1,1))[:,0]\n",
    "    \n",
    "    # make zero the content no longer avilable\n",
    "    scores = scores * availability\n",
    "    \n",
    "    similar = sorted(zip(id_editorial_list, scores[id_editorial_simple_list], type_production_list), key=lambda x: -x[1])\n",
    "    \n",
    "    con_id = similar[0][0]\n",
    "    \n",
    "    return similar[1:21], con_id # return 20, skipping first (i.e. itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 55s, sys: 33.8 s, total: 17min 29s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the output for dynamoDB table\n",
    "output = []\n",
    "\n",
    "for index, i in enumerate(id_editorial_simple_list): \n",
    "    \n",
    "    if availability[index] == 1: # check if content is available otherwise those recommendations will be wrong due to having multiplied scores by zero for unavailable content\n",
    "    \n",
    "        recs, con_id = more_like_this(i)\n",
    "\n",
    "        output_rec = {}\n",
    "        for r in recs:\n",
    "\n",
    "            output_rec[r[0]] = {\n",
    "                'score' : round(float(r[1]), 5),\n",
    "                'type' : r[2],\n",
    "                's_dt' : date_today,\n",
    "                'c_v' : code_version\n",
    "            }\n",
    "\n",
    "        output.append([con_id, output_rec])\n",
    "\n",
    "output_df = pd.DataFrame(output,columns=['content','recommendations'])\n",
    "\n",
    "output_df['recommendations'] = output_df['recommendations'].apply(lambda x: json.dumps(x)) # if already a dict\n",
    "\n",
    "# remove any duplicates; these can still occur if some content has exactly the same watch history as other and gets most similar item itself and other stuff too\n",
    "output_df = output_df.drop_duplicates(subset=['content']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBJ1003714HVOD</td>\n",
       "      <td>{\"BBJ836608HVOD\": {\"score\": 0.9747964143753052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBJ1009533HVOD</td>\n",
       "      <td>{\"BBJ359877HVOD\": {\"score\": 0.9851045608520508...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBJ1009538HVOD</td>\n",
       "      <td>{\"BBJ1471735A\": {\"score\": 0.9725130796432495, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBJ1009541HVOD</td>\n",
       "      <td>{\"BBJ1728633A\": {\"score\": 0.9508183598518372, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBJ1009544HVOD</td>\n",
       "      <td>{\"BBJ1775457A\": {\"score\": 0.9711093902587891, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          content                                    recommendations\n",
       "0  BBJ1003714HVOD  {\"BBJ836608HVOD\": {\"score\": 0.9747964143753052...\n",
       "1  BBJ1009533HVOD  {\"BBJ359877HVOD\": {\"score\": 0.9851045608520508...\n",
       "2  BBJ1009538HVOD  {\"BBJ1471735A\": {\"score\": 0.9725130796432495, ...\n",
       "3  BBJ1009541HVOD  {\"BBJ1728633A\": {\"score\": 0.9508183598518372, ...\n",
       "4  BBJ1009544HVOD  {\"BBJ1775457A\": {\"score\": 0.9711093902587891, ..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>BBJ2788647A</td>\n",
       "      <td>{\"BBJ2804011A\": {\"score\": 0.9798159599304199, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          content                                    recommendations\n",
       "2614  BBJ2788647A  {\"BBJ2804011A\": {\"score\": 0.9798159599304199, ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df[output_df['content'] == 'BBJ2788647A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'EE3D88D797C23EC8',\n",
       "  'HostId': '15OycvYdN94vAgBHowybnwbsGCjxwQLlGOJYs9NAhiAh0V701gzy0HXyRb3EVhQ4l5zL/F0ax6k=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '15OycvYdN94vAgBHowybnwbsGCjxwQLlGOJYs9NAhiAh0V701gzy0HXyRb3EVhQ4l5zL/F0ax6k=',\n",
       "   'x-amz-request-id': 'EE3D88D797C23EC8',\n",
       "   'date': 'Mon, 07 Dec 2020 10:36:47 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"955c24a994f4b2c96280fae56c124436\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"955c24a994f4b2c96280fae56c124436\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save output to S3\n",
    "bucket = 'bt-data-science-playground' # already created on S3\n",
    "csv_buffer = StringIO()\n",
    "output_df.to_csv(csv_buffer, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'bt-tv-recommendation-system/output/morelikethis/test_data_MoreLikeThis.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some tests with real titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_user</th>\n",
       "      <th>type_asset</th>\n",
       "      <th>event_date</th>\n",
       "      <th>id_editorial</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_entitlement</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>eventStrength</th>\n",
       "      <th>rating_n</th>\n",
       "      <th>type_production</th>\n",
       "      <th>id_user_simple</th>\n",
       "      <th>id_editorial_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31659383</th>\n",
       "      <td>V3009418006</td>\n",
       "      <td>film</td>\n",
       "      <td>2020-12-06 18:37:21</td>\n",
       "      <td>BBJ2788647A</td>\n",
       "      <td>An American Pickle</td>\n",
       "      <td>film</td>\n",
       "      <td>2025-12-31 23:59:00</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>1027898</td>\n",
       "      <td>7247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_user type_asset          event_date id_editorial  \\\n",
       "31659383  V3009418006       film 2020-12-06 18:37:21  BBJ2788647A   \n",
       "\n",
       "                       title  type            end_date   genre rating  \\\n",
       "31659383  An American Pickle  film 2025-12-31 23:59:00  Comedy     12   \n",
       "\n",
       "         type_entitlement Unnamed: 2  eventStrength  rating_n type_production  \\\n",
       "31659383             VIEW        NaN              1         2         PROGRAM   \n",
       "\n",
       "          id_user_simple  id_editorial_simple  \n",
       "31659383         1027898                 7247  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_implicit[data_implicit['title'] == 'An American Pickle'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An American Pickle\n",
      "\n",
      "Spontaneous\n",
      "Proxima\n",
      "Rent-a-Pal\n",
      "Miss Juneteenth\n",
      "Lucky Grandma\n",
      "Spree\n",
      "London Unplugged\n",
      "Stage Mother\n",
      "An Accidental Studio\n",
      "Z for Zachariah\n",
      "Totally Under Control\n",
      "3 Days with Dad\n",
      "Photograph\n",
      "Top End Wedding\n",
      "Harpoon\n",
      "The Stanford Prison Experiment\n",
      "Making Waves: The Art of Cinematic Sound\n",
      "Big Time Adolescence\n",
      "Train To Busan Presents: Peninsula\n",
      "Anomalisa\n"
     ]
    }
   ],
   "source": [
    "recs, con_id = more_like_this(7247)\n",
    "print(data_implicit[data_implicit['id_editorial'] == con_id]['title'].tolist()[0])\n",
    "print('')\n",
    "for t in recs:\n",
    "    print(data_implicit[data_implicit['id_editorial'] == t[0]]['title'].tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_contents = np.shape(model.item_factors)[0] # do it for all\n",
    "\n",
    "content_vecs_T = model.item_factors.T\n",
    "person_vecs = model.user_factors\n",
    "\n",
    "def for_you(person_id):\n",
    "    \n",
    "    # Get the interactions scores from the sparse person content matrix\n",
    "    person_interactions = sparse_person_content[person_id,:].toarray()\n",
    "\n",
    "    # Add 1 to everything, so that articles with no interaction yet become equal to 1\n",
    "    person_interactions = person_interactions.reshape(-1) + 1\n",
    "\n",
    "    # Make articles already interacted zero\n",
    "    person_interactions[person_interactions > 1] = 0\n",
    "\n",
    "    # Get dot product of person vector and all content vectors\n",
    "    rec_vector = person_vecs[person_id,:].dot(content_vecs_T)\n",
    "\n",
    "    rec_vector = MinMaxScaler().fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "\n",
    "    # Multiply by zero the scores of items already interacted with\n",
    "    recommend_vector = person_interactions * rec_vector\n",
    "    \n",
    "    # make zero the content no longer avilable\n",
    "    recommend_vector = recommend_vector * availability\n",
    "    \n",
    "    recs = sorted(zip(id_editorial_list, recommend_vector[id_editorial_simple_list], type_production_list), key=lambda x: -x[1])\n",
    "    \n",
    "    user_id = id_user_list[id_user_simple_list.index(person_id)]\n",
    "    \n",
    "    return recs[:50], user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 190 ms, sys: 15 ms, total: 205 ms\n",
      "Wall time: 32.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create the output for dynamoDB table\n",
    "output = []\n",
    "\n",
    "for i in [1039465]:#id_user_simple_list[:1000]: \n",
    "    \n",
    "    recs, user_id = for_you(i)\n",
    "    \n",
    "    output_rec = {}\n",
    "    for r in recs:\n",
    "        \n",
    "        output_rec[r[0]] = {\n",
    "            'score' : roudn(float(r[1]), 5),\n",
    "            'type' : r[2],\n",
    "            's_dt' : date_today,\n",
    "            'c_v' : code_version\n",
    "        }\n",
    "    \n",
    "    output.append([user_id, output_rec])\n",
    "\n",
    "output_df = pd.DataFrame(output,columns=['user','recommendations'])\n",
    "\n",
    "output_df['recommendations'] = output_df['recommendations'].apply(lambda x: json.dumps(x)) # if already a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V3578624855</td>\n",
       "      <td>{\"movida_1979\": {\"score\": 0.9585089087486267, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user                                    recommendations\n",
       "0  V3578624855  {\"movida_1979\": {\"score\": 0.9585089087486267, ..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '985F41DE62C160E5',\n",
       "  'HostId': '9edIoUeLt5eDNVyJ/Ala5ukp08fVK1QNQwsY7/UffyaG5SNVrk3vshsH5ilpKiuvBZJ0XAXlh4o=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '9edIoUeLt5eDNVyJ/Ala5ukp08fVK1QNQwsY7/UffyaG5SNVrk3vshsH5ilpKiuvBZJ0XAXlh4o=',\n",
       "   'x-amz-request-id': '985F41DE62C160E5',\n",
       "   'date': 'Tue, 08 Dec 2020 12:32:22 GMT',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'etag': '\"8bc73315e131dac7a97fcaf8c0ffeaef\"',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"8bc73315e131dac7a97fcaf8c0ffeaef\"',\n",
       " 'ServerSideEncryption': 'AES256'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save output to S3\n",
    "bucket = 'bt-data-science-playground' # already created on S3\n",
    "csv_buffer = StringIO()\n",
    "output_df.to_csv(csv_buffer, sep='\\t', index=False, quoting=csv.QUOTE_NONE)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'bt-tv-recommendation-system/output/foryou/test_data_ForYou.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some tests with real users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_user</th>\n",
       "      <th>type_asset</th>\n",
       "      <th>event_date</th>\n",
       "      <th>id_editorial</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_entitlement</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>eventStrength</th>\n",
       "      <th>rating_n</th>\n",
       "      <th>type_production</th>\n",
       "      <th>id_user_simple</th>\n",
       "      <th>id_editorial_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7511428</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2019-07-21 15:10:19</td>\n",
       "      <td>BBJ316695HVOD</td>\n",
       "      <td>Cars 2</td>\n",
       "      <td>film</td>\n",
       "      <td>2022-01-02 23:59:00</td>\n",
       "      <td>Animation</td>\n",
       "      <td>u</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>0</td>\n",
       "      <td>7730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20209666</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2019-02-17 17:58:41</td>\n",
       "      <td>BBJ307162HVOD</td>\n",
       "      <td>Divergent</td>\n",
       "      <td>film</td>\n",
       "      <td>2021-08-16 22:59:00</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>0</td>\n",
       "      <td>7643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24463565</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2019-02-17 15:12:49</td>\n",
       "      <td>movida_10027636</td>\n",
       "      <td>Avengers: Infinity War [Bonus Edition]</td>\n",
       "      <td>collection</td>\n",
       "      <td>2025-12-31 23:59:00</td>\n",
       "      <td>Action</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>COLLECTION</td>\n",
       "      <td>0</td>\n",
       "      <td>14225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25904874</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>episode</td>\n",
       "      <td>2020-06-26 20:13:11</td>\n",
       "      <td>movida_57300</td>\n",
       "      <td>MTV Cribs: Footballers Stay Home Series 1</td>\n",
       "      <td>season</td>\n",
       "      <td>2020-07-22 22:59:00</td>\n",
       "      <td>Reality</td>\n",
       "      <td>pg</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BRAND</td>\n",
       "      <td>0</td>\n",
       "      <td>18322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451157</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2020-01-10 18:08:38</td>\n",
       "      <td>BBJ339679HVOD</td>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>film</td>\n",
       "      <td>2022-01-02 23:59:00</td>\n",
       "      <td>Action</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>0</td>\n",
       "      <td>7848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31603714</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2019-03-22 16:19:36</td>\n",
       "      <td>movida_10027636</td>\n",
       "      <td>Avengers: Infinity War [Bonus Edition]</td>\n",
       "      <td>collection</td>\n",
       "      <td>2025-12-31 23:59:00</td>\n",
       "      <td>Action</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>COLLECTION</td>\n",
       "      <td>0</td>\n",
       "      <td>14225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31603758</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2019-03-22 15:49:03</td>\n",
       "      <td>movida_10027636</td>\n",
       "      <td>Avengers: Infinity War [Bonus Edition]</td>\n",
       "      <td>collection</td>\n",
       "      <td>2025-12-31 23:59:00</td>\n",
       "      <td>Action</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>COLLECTION</td>\n",
       "      <td>0</td>\n",
       "      <td>14225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34804100</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2018-08-04 11:03:45</td>\n",
       "      <td>BBJ314269HVOD</td>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>film</td>\n",
       "      <td>2025-12-31 23:59:00</td>\n",
       "      <td>Action</td>\n",
       "      <td>15</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>0</td>\n",
       "      <td>7654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43925453</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>episode</td>\n",
       "      <td>2019-10-02 21:31:11</td>\n",
       "      <td>movida_10070789</td>\n",
       "      <td>Man City v Zagreb</td>\n",
       "      <td>collection</td>\n",
       "      <td>2021-06-30 22:59:00</td>\n",
       "      <td>Football</td>\n",
       "      <td>u</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>COLLECTION</td>\n",
       "      <td>0</td>\n",
       "      <td>16206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44235449</th>\n",
       "      <td>V1000000000</td>\n",
       "      <td>film</td>\n",
       "      <td>2020-01-19 13:43:13</td>\n",
       "      <td>BBJ1060095HVOD</td>\n",
       "      <td>The Hobbit: The Desolation of Smaug</td>\n",
       "      <td>film</td>\n",
       "      <td>2022-01-02 23:59:00</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>12</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>PROGRAM</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_user type_asset          event_date     id_editorial  \\\n",
       "7511428   V1000000000       film 2019-07-21 15:10:19    BBJ316695HVOD   \n",
       "20209666  V1000000000       film 2019-02-17 17:58:41    BBJ307162HVOD   \n",
       "24463565  V1000000000       film 2019-02-17 15:12:49  movida_10027636   \n",
       "25904874  V1000000000    episode 2020-06-26 20:13:11     movida_57300   \n",
       "27451157  V1000000000       film 2020-01-10 18:08:38    BBJ339679HVOD   \n",
       "31603714  V1000000000       film 2019-03-22 16:19:36  movida_10027636   \n",
       "31603758  V1000000000       film 2019-03-22 15:49:03  movida_10027636   \n",
       "34804100  V1000000000       film 2018-08-04 11:03:45    BBJ314269HVOD   \n",
       "43925453  V1000000000    episode 2019-10-02 21:31:11  movida_10070789   \n",
       "44235449  V1000000000       film 2020-01-19 13:43:13   BBJ1060095HVOD   \n",
       "\n",
       "                                              title        type  \\\n",
       "7511428                                      Cars 2        film   \n",
       "20209666                                  Divergent        film   \n",
       "24463565     Avengers: Infinity War [Bonus Edition]  collection   \n",
       "25904874  MTV Cribs: Footballers Stay Home Series 1      season   \n",
       "27451157                    Guardians of the Galaxy        film   \n",
       "31603714     Avengers: Infinity War [Bonus Edition]  collection   \n",
       "31603758     Avengers: Infinity War [Bonus Edition]  collection   \n",
       "34804100                        Saving Private Ryan        film   \n",
       "43925453                          Man City v Zagreb  collection   \n",
       "44235449        The Hobbit: The Desolation of Smaug        film   \n",
       "\n",
       "                    end_date      genre rating type_entitlement Unnamed: 2  \\\n",
       "7511428  2022-01-02 23:59:00  Animation      u             VIEW        NaN   \n",
       "20209666 2021-08-16 22:59:00     Sci-Fi     12             VIEW        NaN   \n",
       "24463565 2025-12-31 23:59:00     Action     12             VIEW        NaN   \n",
       "25904874 2020-07-22 22:59:00    Reality     pg             VIEW        NaN   \n",
       "27451157 2022-01-02 23:59:00     Action     12             VIEW        NaN   \n",
       "31603714 2025-12-31 23:59:00     Action     12             VIEW        NaN   \n",
       "31603758 2025-12-31 23:59:00     Action     12             VIEW        NaN   \n",
       "34804100 2025-12-31 23:59:00     Action     15             VIEW        NaN   \n",
       "43925453 2021-06-30 22:59:00   Football      u             VIEW        NaN   \n",
       "44235449 2022-01-02 23:59:00    Fantasy     12             VIEW        NaN   \n",
       "\n",
       "          eventStrength  rating_n type_production  id_user_simple  \\\n",
       "7511428               1         0         PROGRAM               0   \n",
       "20209666              1         2         PROGRAM               0   \n",
       "24463565              1         2      COLLECTION               0   \n",
       "25904874              1         1           BRAND               0   \n",
       "27451157              1         2         PROGRAM               0   \n",
       "31603714              1         2      COLLECTION               0   \n",
       "31603758              1         2      COLLECTION               0   \n",
       "34804100              1         3         PROGRAM               0   \n",
       "43925453              1         0      COLLECTION               0   \n",
       "44235449              1         2         PROGRAM               0   \n",
       "\n",
       "          id_editorial_simple  \n",
       "7511428                  7730  \n",
       "20209666                 7643  \n",
       "24463565                14225  \n",
       "25904874                18322  \n",
       "27451157                 7848  \n",
       "31603714                14225  \n",
       "31603758                14225  \n",
       "34804100                 7654  \n",
       "43925453                16206  \n",
       "44235449                  463  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_implicit[data_implicit['id_user_simple'] == 0].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Legend of Tarzan\n",
      "Avengers: Endgame [Bonus Edition]\n",
      "Deadpool 2 [Bonus Edition]\n",
      "Deadpool 2\n",
      "Black Panther\n",
      "Venom\n",
      "Thor: Ragnarok [Bonus Edition]\n",
      "Ant-Man and the Wasp\n",
      "Solo: A Star Wars Story [Bonus Edition]\n",
      "Star Wars: The Last Jedi [Bonus Edition]\n",
      "SNATCH Series 1\n",
      "Ready Player One\n",
      "Game of Thrones Series 1\n",
      "The Harry Potter Complete Collection\n",
      "Ready Player One [Bonus Edition]\n",
      "Guardians of the Galaxy Vol. 2 [Bonus Edition]\n",
      "Bohemian Rhapsody [Bonus Edition]\n",
      "A Star Is Born\n",
      "John Wick: Chapter 3 - Parabellum\n",
      "Pacific Rim: Uprising\n",
      "Bumblebee\n",
      "Spider-Man: Homecoming\n",
      "Fantastic Beasts And Where To Find Them\n",
      "Shazam!\n",
      "Johnny English Strikes Again\n",
      "Star Wars: The Rise of Skywalker [Bonus Edition]\n",
      "Avengers Assemble\n",
      "Star Wars: The Force Awakens [Bonus Edition]\n",
      "Justice League\n",
      "The House With A Clock In Its Walls\n",
      "Incredibles 2 [Bonus Edition]\n",
      "UEFA Champions League 2018/19\n",
      "Jumanji: The Next Level\n",
      "Kingsman: The Golden Circle\n",
      "Ralph Breaks the Internet\n",
      "Rogue One: A Star Wars Story [Bonus Edition]\n",
      "John Wick: Chapter 2\n",
      "WWE Raw\n",
      "WWE SmackDown\n",
      "How To Train Your Dragon: The Hidden World\n",
      "Aladdin\n",
      "Angel Has Fallen\n",
      "A Quiet Place\n",
      "Avengers: Age of Ultron\n",
      "Mortal Engines\n",
      "Deadpool\n",
      "John Wick\n",
      "Joker\n",
      "Jurassic World\n",
      "Godzilla: King Of The Monsters\n"
     ]
    }
   ],
   "source": [
    "recs, con_id = for_you(0)\n",
    "\n",
    "for t in recs:\n",
    "     print(data_implicit[data_implicit['id_editorial'] == t[0]]['title'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_user</th>\n",
       "      <th>type_asset</th>\n",
       "      <th>event_date</th>\n",
       "      <th>id_editorial</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_entitlement</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>eventStrength</th>\n",
       "      <th>rating_n</th>\n",
       "      <th>type_production</th>\n",
       "      <th>id_user_simple</th>\n",
       "      <th>id_editorial_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102318</th>\n",
       "      <td>V2283739102</td>\n",
       "      <td>episode</td>\n",
       "      <td>2019-11-11 16:13:39</td>\n",
       "      <td>movida_29422</td>\n",
       "      <td>Sesame Street ABC's Series 1</td>\n",
       "      <td>season</td>\n",
       "      <td>2021-10-27 22:59:00</td>\n",
       "      <td>2 - 5 Years</td>\n",
       "      <td>u</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BRAND</td>\n",
       "      <td>45140</td>\n",
       "      <td>17941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_user type_asset          event_date  id_editorial  \\\n",
       "102318  V2283739102    episode 2019-11-11 16:13:39  movida_29422   \n",
       "\n",
       "                               title    type            end_date        genre  \\\n",
       "102318  Sesame Street ABC's Series 1  season 2021-10-27 22:59:00  2 - 5 Years   \n",
       "\n",
       "       rating type_entitlement Unnamed: 2  eventStrength  rating_n  \\\n",
       "102318      u             VIEW        NaN              1         0   \n",
       "\n",
       "       type_production  id_user_simple  id_editorial_simple  \n",
       "102318           BRAND           45140                17941  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_implicit[data_implicit['id_user'] == 'V2283739102'].head(1) # Sam's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilder v Fury II\n",
      "Premier League World 2020/21\n",
      "UEFA Champions League 2019/20\n",
      "Frozen II [Bonus Edition]\n",
      "Ben 10: Alien Worlds Series 3\n",
      "Mighty Mike Series 1\n",
      "Scooby-Doo and Guess Who? Series 1\n",
      "Teen Titans Go! Series 1\n",
      "WWE Raw\n",
      "WWE SmackDown\n",
      "Scooby-Doo! Mystery Incorporated Series 2\n",
      "NinjaGo Series 1\n",
      "The Amazing World of Gumball Series 5\n",
      "Angry Birds Blues Series 1\n",
      "Be Cool, Scooby-Doo! Series 1\n",
      "Taffy Series 1\n",
      "Toy Story 4 [Bonus Edition]\n",
      "Greavsie\n",
      "The Scooby Doo Show Series 1\n",
      "Onward\n",
      "Tom and Jerry Tales Series 1\n",
      "Scooby Doo Where Are You! Series 2\n",
      "Jumanji: The Next Level\n",
      "Dorothy and the Wizard of Oz Series 1\n",
      "Peppa Pig Series 2\n",
      "Aladdin\n",
      "Teen Titans Go!\n",
      "Uncle Grandpa Series 1\n",
      "Paw Patrol Series 5\n",
      "ESPN Films: 30 for 30\n",
      "Ben & Holly's Little Kingdom Series 1\n",
      "Fireman Sam Series 9\n",
      "Toy Story 4\n",
      "Wilder v Fury Highlights\n",
      "Joker\n",
      "Top 10 UCL Goals Messi\n",
      "Scooby-Doo!\n",
      "ZeZe Zebra Nursery Rhymes\n",
      "Upgrade\n",
      "The Batman Series 1\n",
      "The Looney Tunes Show Series 1\n",
      "Super Healthy Monsters Series 1\n",
      "UEFA Champions League 2020/21\n",
      "XLR8\n",
      "The Lion King [Bonus Edition]\n",
      "Dolittle\n",
      "Tom and Jerry\n",
      "The Lion King (2019)\n",
      "Four Arms\n",
      "Pokemon Detective Pikachu\n"
     ]
    }
   ],
   "source": [
    "recs, con_id = for_you(45140)\n",
    "\n",
    "for t in recs:\n",
    "     print(data_implicit[data_implicit['id_editorial'] == t[0]]['title'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_user</th>\n",
       "      <th>type_asset</th>\n",
       "      <th>event_date</th>\n",
       "      <th>id_editorial</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>end_date</th>\n",
       "      <th>genre</th>\n",
       "      <th>rating</th>\n",
       "      <th>type_entitlement</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>eventStrength</th>\n",
       "      <th>rating_n</th>\n",
       "      <th>type_production</th>\n",
       "      <th>id_user_simple</th>\n",
       "      <th>id_editorial_simple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68100</th>\n",
       "      <td>V3578624855</td>\n",
       "      <td>episode</td>\n",
       "      <td>2018-11-01 09:30:37</td>\n",
       "      <td>movida_10018585</td>\n",
       "      <td>SpongeBob SquarePants Series 11</td>\n",
       "      <td>season</td>\n",
       "      <td>2020-02-03 04:30:00</td>\n",
       "      <td>6 Years +</td>\n",
       "      <td>u</td>\n",
       "      <td>VIEW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BRAND</td>\n",
       "      <td>1039465</td>\n",
       "      <td>13711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id_user type_asset          event_date     id_editorial  \\\n",
       "68100  V3578624855    episode 2018-11-01 09:30:37  movida_10018585   \n",
       "\n",
       "                                 title    type            end_date      genre  \\\n",
       "68100  SpongeBob SquarePants Series 11  season 2020-02-03 04:30:00  6 Years +   \n",
       "\n",
       "      rating type_entitlement Unnamed: 2  eventStrength  rating_n  \\\n",
       "68100      u             VIEW        NaN              1         0   \n",
       "\n",
       "      type_production  id_user_simple  id_editorial_simple  \n",
       "68100           BRAND         1039465                13711  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_implicit[data_implicit['id_user'] == 'V3578624855'].head(1) # Peter's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game of Thrones Series 4\n",
      "TUF: Season 28\n",
      "IT\n",
      "Daddy's Home 2\n",
      "The Harry Potter Complete Collection\n",
      "Ready Player One [Bonus Edition]\n",
      "Deadpool 2 [Bonus Edition]\n",
      "Young Sheldon Series 1\n",
      "Kingsman: The Golden Circle\n",
      "Shazam!\n",
      "UFC Ultimate Knockouts\n",
      "Home Alone\n",
      "Elf\n",
      "Mean Girls\n",
      "Home Alone 2: Lost in New York\n",
      "UFC 25 Greatest Fights\n",
      "Suicide Squad [Bonus Edition]\n",
      "Henry Danger Series 5\n",
      "Lost Series 1\n",
      "The Office (US) Series 7\n",
      "Goosebumps 2: Haunted Halloween\n",
      "Pokemon Detective Pikachu\n",
      "The Simpsons Movie\n",
      "IT Chapter Two\n",
      "UFC 244\n",
      "Harry Potter and the Philosopher's Stone\n",
      "Harry Potter and the Chamber of Secrets\n",
      "Hocus Pocus\n",
      "Justice League\n",
      "Grease\n",
      "UFC Top 10s\n",
      "Fantastic Beasts And Where To Find Them\n",
      "Apple & Onion Series 1\n",
      "We Bare Bears Series 2\n",
      "The Flash Series 2\n",
      "Ant-Man and the Wasp\n",
      "Wonder Woman\n",
      "Bumblebee\n",
      "Avengers: Age of Ultron\n",
      "UFC 230\n",
      "Tim Burton's The Nightmare Before Christmas\n",
      "Creed II\n",
      "Captain America: Civil War [Bonus Edition]\n",
      "UFC 235\n",
      "The Lord of the Rings Trilogy\n",
      "Instant Family\n",
      "The Muppet Christmas Carol\n",
      "Good Boys\n",
      "Pitch Perfect 3\n",
      "The Addams Family\n"
     ]
    }
   ],
   "source": [
    "recs, con_id = for_you(1039465)\n",
    "\n",
    "for t in recs:\n",
    "     print(data_implicit[data_implicit['id_editorial'] == t[0]]['title'].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
